---
title: "Model parameterisation of Black Sea Turbot using the SAM assessment model"
author: "Niels Hintzen & Thomas Brunel"
date:   "7th of July 2019"
output: html_document
---

```{r, eval=T, results="hide", echo=TRUE, message=FALSE, warning=FALSE}
library(FLCore)
library(FLSAM) #note that FLSAM relies on install_github("fishfollower/SAM",ref="components")
library(FLEDA)
options(width = 110)
rm(list=ls())
setwd("D:/Repository/MSE_Adriatic/BST/")
source("BST_additionalPlottingRoutines.r")
```

# Intro

In this section, we will use the data from the previous analyses (data selection) and tune all parameters such that we get an optimal model.
There are a couple of parameters we can play with:

* F random walk variances
* Correlation structure of the F random walks
* Catchabilities of the surveys
* Observation variances of all data sources
* Correlation within surveys

We take these in this order and use both retrospectives as well as AIC criteria for model improvement. We consider it here as a one-way-street.
As such, we do not go back and check upon a parameter setting if we find an improvement in a later step.

First we need to get the data in the right shape, but we're not showing it here anymore (code is in Rmarkdown document though).

```{r, eval=T, echo=FALSE, message=FALSE, warning=FALSE}

BST                 <- readFLStock("TURT_50_IUU5_2018IND.DAT",no.discards=TRUE)
BST@catch           <- BST@landings
units(BST)[1:17]    <- as.list(c(rep(c("tonnes","thousands","kg"),4),
                                 rep("NA",2),"f",rep("NA",2)))
BST@discards.n[]    <- 0; BST@discards.wt[] <- 0; BST@discards <- computeDiscards(BST)
BST@name            <- "Black Sea Turbot"

range(BST)[c("minfbar","maxfbar")]    <- c(4,8)
BST                                   <- setPlusGroup(BST,9)
BST                                   <- window(BST,start=1989)

BST.tun             <- readFLIndices("TURT_50_IUU5_2018_allTUN.DAT")

#- Two surveys were split up, we combine them here again
BST.tun[["BG Spring Trawl survey - Abun"]]                              <- window(BST.tun[["BG Spring Trawl survey - Abun"]],end=2018)
BST.tun[["BG Spring Trawl survey - Abun"]]@index[ac(1:8),ac(2016:2018)] <- BST.tun[["BG Spring Trawl survey2 - Abun"]]@index[,ac(2016:2018)]
BST.tun[["BG Autumn Trawl survey - Abun"]]                              <- window(BST.tun[["BG Autumn Trawl survey - Abun"]],end=2018)
BST.tun[["BG Autumn Trawl survey - Abun"]]@index[,ac(2014:2018)]        <- BST.tun[["BG Autumn Trawl survey2 - Abun"]]@index[,ac(2014:2018)]
BST.tun             <- BST.tun[c(1:7,9)]

BST.tun[["RO Trawl Survey"]]                <- BST.tun[["RO Trawl Survey"]][ac(1:8),]
BST.tun[["UKR Trawl survey West"]]          <- BST.tun[["UKR Trawl survey West"]][ac(1:8),ac(c(1989:1994,1998,2001:2007))]
BST.tun[["UKR Trawl survey East"]]          <- BST.tun[["UKR Trawl survey East"]][ac(1:8),ac(c(1989:1994,1998,2001:2006))]
BST.tun[["TR Trawl survey (East) autumn"]]  <- BST.tun[["TR Trawl survey (East) autumn"]][ac(1:5),ac(c(2010:2011,2017:2018))]
BST.tun[["TR Trawl survey (East)spring"]]   <- BST.tun[["TR Trawl survey (East)spring"]][ac(1:6),ac(c(2010:2011,2017:2018))]
BST.tun[["TR Trawl survey (west)"]]         <- BST.tun[["TR Trawl survey (west)"]][ac(1:5),ac(c(2011,2013:2014,2016))]
BST.tun[["BG Spring Trawl survey - Abun"]]  <- BST.tun[["BG Spring Trawl survey - Abun"]][ac(1:8),ac(c(2006:2012,2016:2018))]
BST.tun[["BG Autumn Trawl survey - Abun"]]  <- BST.tun[["BG Autumn Trawl survey - Abun"]][ac(1:8),ac(c(2006:2012,2014:2018))]
BST.tun   <- lapply(BST.tun,function(x) {x@type <- "number"; return(x)})

for(iTun in 1:length(BST.tun))
  BST.tun[[iTun]]@index@.Data[which(BST.tun[[iTun]]@index[] <= 0.02)] <- NA


BST.ctrl  <- FLSAM.control(BST,BST.tun)

BST.ctrl@catchabilities["RO Trawl Survey",ac(1:8)]                <- c(1:3,rep(4,5))
BST.ctrl@catchabilities["UKR Trawl survey West",ac(1:8)]          <- c(1,1,2,3,4,5,6,7)       + 101
BST.ctrl@catchabilities["UKR Trawl survey East",ac(1:8)]          <- c(1,1,2,3,4,rep(5,3))    + 201
BST.ctrl@catchabilities["TR Trawl survey (East) autumn",ac(1:5)]  <- c(1,2,3,4,4)             + 301
BST.ctrl@catchabilities["TR Trawl survey (East)spring",ac(1:6)]   <- c(1,1,2,2,3,3)           + 401
BST.ctrl@catchabilities["TR Trawl survey (west)",ac(1:5)]         <- c(1,2,3,3,3)             + 501
BST.ctrl@catchabilities["BG Spring Trawl survey - Abun",ac(1:8)]  <- c(1,2,3,3,4,4,5,5)       + 601
BST.ctrl@catchabilities["BG Autumn Trawl survey - Abun",ac(1:8)]  <- c(1,2,3,4,rep(5,4))      + 701

BST.ctrl@obs.vars["catch unique",]                                <- c(1,2,3,3,3,3,3,3,4)
BST.ctrl@obs.vars["RO Trawl Survey",ac(1:8)]                      <- c(1,1,rep(2,5),3)    + 101
BST.ctrl@obs.vars["UKR Trawl survey West",ac(1:8)]                <- c(1,1,2,2,3,4,5,5)   + 201
BST.ctrl@obs.vars["UKR Trawl survey East",ac(1:8)]                <- c(1)                 + 301
BST.ctrl@obs.vars["TR Trawl survey (East) autumn",ac(1:5)]        <- c(1,1,2,3,3)         + 401
BST.ctrl@obs.vars["TR Trawl survey (East)spring",ac(1:6)]         <- c(1,1,2,2,3,3)       + 501
BST.ctrl@obs.vars["TR Trawl survey (west)",ac(1:5)]               <- c(1,2,3,4,4)         + 601
BST.ctrl@obs.vars["BG Spring Trawl survey - Abun",ac(1:8)]        <- c(rep(1,6),2,3)      + 701
BST.ctrl@obs.vars["BG Autumn Trawl survey - Abun",ac(1:8)]        <- c(1,rep(2,7))        + 801

BST.ctrl <- update(BST.ctrl)

output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl)))
```

There is one feature of SAM that we are not going to use (as it cannot be estimated reliably with the given data) which is the deviation to the survivor equation.
We set this to a low value (i.e. turn the feature off). For this, we need an 'init'  object that we create first, and then the call to the model will become a little
bit more complex, but the code below will guide us.

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
init.sam            <- BST.sam
init.sam@params$value[which(init.sam@params$name=="logSdLogN")[2]] <- -5
#The new bit in the calling the assessment is the second row bit
output <- capture.output(BST.sam <- FLSAM(BST,BST.tun,BST.ctrl,
                                          starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA)))))
```


```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
plot(BST.sam)
print(residual.diagnostics(BST.sam))
BST.ctrl@residuals  <- FALSE
```

This is the starting point for the model refinement. The AIC value to compete against is: `r AIC(BST.sam)`


# F random walk variances

We simply tackle this by giving full freedom to all random walks and cluster those that are similar afterwards

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@f.vars[1,] <- c(1:8,8)
BST.ctrl            <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
fvars <- f.var(BST.sam)
print(xyplot(value+ubnd+lbnd ~ age | fleet,fvars,
             scale=list(alternating=FALSE,y=list(relation="free")),as.table=TRUE,
             type="b",lwd=c(2,1,1),col=c("black","grey","grey"),pch=19,
             main="F random walk variances",ylab="Variance",xlab="Age"))
```

Concluding from this that we can group ages 1 to 2, 5 to 6 and 8 to 9.

```{r, eval=T, echo=FALSE, message=FALSE, warning=FALSE}
BST.ctrl@f.vars[1,]              <- c(1,1,2,3,4,4,5,6,6)
BST.ctrl            <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
```

The AIC drops to `r AIC(BST.sam)`

# F correlations

There are three options here:
1. 0 means that there is no correlation among ages between the F random walk variances
2. 1 means that there is equal correlation among all ages in the F random walk variances
3. 2 means that there is correlation, but it's weighted by the distance in age (default)

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@cor.F      <- as.integer(0)
output              <- capture.output(BST.sam0             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
retrocorF0          <- manualRetro(BST.sam0,BST,BST.tun,BST.ctrl,sam.init=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))
BST.ctrl@cor.F      <- as.integer(1)
output              <- capture.output(BST.sam1             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
retrocorF1          <- manualRetro(BST.sam1,BST,BST.tun,BST.ctrl,sam.init=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))
BST.ctrl@cor.F      <- as.integer(2)
output              <- capture.output(BST.sam2             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
retrocorF2          <- manualRetro(BST.sam2,BST,BST.tun,BST.ctrl,sam.init=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))

BST.samsFcor        <- as(list(BST.sam0,BST.sam1,BST.sam2),"FLSAMs")

storeMohnsRhos      <- matrix(NA,nrow=3,ncol=3,dimnames=list(corF=c(0,1,2),type=c("ssb","fbar","rec")))
storeMohnsRhos[1,1] <- mean(mohns.rho(retrocorF0,ref.year=2018,type="ssb",span=4)[1:4,1])
storeMohnsRhos[2,1] <- mean(mohns.rho(retrocorF1,ref.year=2018,type="ssb",span=4)[1:4,1])
storeMohnsRhos[3,1] <- mean(mohns.rho(retrocorF2,ref.year=2018,type="ssb",span=4)[1:4,1])

storeMohnsRhos[1,2] <- mean(mohns.rho(retrocorF0,ref.year=2018,type="fbar",span=4)[1:4,1])
storeMohnsRhos[2,2] <- mean(mohns.rho(retrocorF1,ref.year=2018,type="fbar",span=4)[1:4,1])
storeMohnsRhos[3,2] <- mean(mohns.rho(retrocorF2,ref.year=2018,type="fbar",span=4)[1:4,1])

storeMohnsRhos[1,3] <- mean(mohns.rho(retrocorF0,ref.year=2018,type="rec",span=4)[1:4,1])
storeMohnsRhos[2,3] <- mean(mohns.rho(retrocorF1,ref.year=2018,type="rec",span=4)[1:4,1])
storeMohnsRhos[3,3] <- mean(mohns.rho(retrocorF2,ref.year=2018,type="rec",span=4)[1:4,1])

plot(retrocorF0,main="Fcor=0")
plot(retrocorF1,main="Fcor=1")
plot(retrocorF2,main="Fcor=2")

print(storeMohnsRhos)


```

The AIC for these runs are: `r AIC(BST.samsFcor)`. The last one is the default value of cor.F = 2. We keep it that way. The retrospective looks better for a model with cor=0,
but it's far less stable in optimization. Perhaps this is the one setting that needs revision near the end.

# Catchabilities of the surveys

We've done this analyses before, but we repeat it here just to make sure, also because we changed some things in the data selection procedures

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@catchabilities["RO Trawl Survey",ac(1:8)]                <- c(1:7,7)       + 101
BST.ctrl@catchabilities["UKR Trawl survey West",ac(1:8)]          <- c(1:7,7)       + 201
BST.ctrl@catchabilities["UKR Trawl survey East",ac(1:8)]          <- c(1:7,7)       + 301
BST.ctrl@catchabilities["TR Trawl survey (East) autumn",ac(1:5)]  <- c(1,2,3,4,4)   + 401
BST.ctrl@catchabilities["TR Trawl survey (East)spring",ac(1:6)]   <- c(1:5,5)       + 501
BST.ctrl@catchabilities["TR Trawl survey (west)",ac(1:5)]         <- c(1:4,4)       + 601
BST.ctrl@catchabilities["BG Spring Trawl survey - Abun",ac(1:8)]  <- c(1:7,7)       + 701
BST.ctrl@catchabilities["BG Autumn Trawl survey - Abun",ac(1:8)]  <- c(1:7,7)       + 801
BST.ctrl <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))

catch <- catchabilities(BST.sam)
print(xyplot(value+ubnd+lbnd ~ age | fleet,catch,
             scale=list(alternating=FALSE,y=list(relation="free")),as.table=TRUE,
             type="b",lwd=c(2,1,1),col=c("black","grey","grey"),pch=19,
             subset=fleet %in% names(BST.tun),
             main="Survey catchability parameters_all",ylab="Catchability",xlab="Age"))
```

There is some binding to do!

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@catchabilities["RO Trawl Survey",ac(1:8)]                <- c(1:4,rep(5,4))
BST.ctrl@catchabilities["UKR Trawl survey West",ac(1:8)]          <- c(1,1,2,3,4,rep(5,3))    + 101
BST.ctrl@catchabilities["UKR Trawl survey East",ac(1:8)]          <- c(1,1,2,3,4,rep(5,3))    + 201
BST.ctrl@catchabilities["TR Trawl survey (East) autumn",ac(1:5)]  <- c(1,2,3,4,4)             + 301
BST.ctrl@catchabilities["TR Trawl survey (East)spring",ac(1:6)]   <- c(1,2,3,3,4,4)           + 401
BST.ctrl@catchabilities["TR Trawl survey (west)",ac(1:5)]         <- c(1,2,3,3,3)             + 501
BST.ctrl@catchabilities["BG Spring Trawl survey - Abun",ac(1:8)]  <- c(1,2,3,3,rep(4,4))      + 601
BST.ctrl@catchabilities["BG Autumn Trawl survey - Abun",ac(1:8)]  <- c(1,2,3,4,rep(5,4))      + 701
BST.ctrl                                                          <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))

```

Finally, we get to an AIC of `r AIC(BST.sam)`

# Observation variances of all data sources

Similar to the steps under the data selection, we repeat it here and open up all parameters and bind them together afterwards

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@obs.vars["catch unique",]                                <- c(1:8,8)
BST.ctrl@obs.vars["RO Trawl Survey",ac(1:8)]                      <- c(1:7,7)   + 101
BST.ctrl@obs.vars["UKR Trawl survey West",ac(1:8)]                <- c(1:7,7)   + 201
BST.ctrl@obs.vars["UKR Trawl survey East",ac(1:8)]                <- c(1:7,7)   + 301
BST.ctrl@obs.vars["TR Trawl survey (East) autumn",ac(1:5)]        <- c(1:4,4)   + 401
BST.ctrl@obs.vars["TR Trawl survey (East)spring",ac(1:6)]         <- c(1:5,5)   + 501
BST.ctrl@obs.vars["TR Trawl survey (west)",ac(1:5)]               <- c(1:4,4)   + 601
BST.ctrl@obs.vars["BG Spring Trawl survey - Abun",ac(1:8)]        <- c(1:7,7)   + 701
BST.ctrl@obs.vars["BG Autumn Trawl survey - Abun",ac(1:8)]        <- c(1:7,7)   + 801

BST.ctrl <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
```

Also here, some binding to do!

```{r, eval=T, echo=FALSE, message=FALSE, warning=FALSE}
obsvar.plot(BST.sam)

obsvars <- obs.var(BST.sam)
print(xyplot(value+ubnd+lbnd ~ age | fleet,obsvars,
             scale=list(alternating=FALSE,y=list(relation="free")),as.table=TRUE,
             type="b",lwd=c(2,1,1),col=c("black","grey","grey"),pch=19,
             main="Observation variances",ylab="Observation variance",xlab="Age"))
```

From the first picture, there are no obvious age-classes that should be omitted as they are simply too noisy. Obvioulsy, those age-classes of surveys in the
right-hand side are candidates, but not directly.

Clearly, there is something strange going on with the catch and the Turkish trawl survey east in spring (needs some parameters to be bound together).

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.ctrl@obs.vars["catch unique",]                                <- c(1,1,rep(2,5),3,3)
BST.ctrl@obs.vars["RO Trawl Survey",ac(1:8)]                      <- c(1,1,rep(2,3),rep(3,3))   + 101
BST.ctrl@obs.vars["UKR Trawl survey West",ac(1:8)]                <- c(1,1,2,2,2,2,3,3)         + 201
BST.ctrl@obs.vars["UKR Trawl survey East",ac(1:8)]                <- c(1,1,2,3,3,3,4,4)         + 301
BST.ctrl@obs.vars["TR Trawl survey (East) autumn",ac(1:5)]        <- c(1,1,2,3,3)               + 401
BST.ctrl@obs.vars["TR Trawl survey (East)spring",ac(1:6)]         <- c(1,1,2,2,3,3)             + 501
BST.ctrl@obs.vars["TR Trawl survey (west)",ac(1:5)]               <- c(1,1,1,2,2)               + 601
BST.ctrl@obs.vars["BG Spring Trawl survey - Abun",ac(1:8)]        <- c(rep(1,6),2,2)            + 701
BST.ctrl@obs.vars["BG Autumn Trawl survey - Abun",ac(1:8)]        <- c(1,rep(2,7))              + 801
BST.ctrl    <- update(BST.ctrl)
output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))

```

Finally, we get to an AIC of `r AIC(BST.sam)`


# Correlation within surveys

The final step is to allow for correlation structures in the surveys (e.g. correction for year effects)
We add them one-by-one, but do this in a specific order. We start with the least performing survey (from observation variance).

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
library(doBy)
print(orderBy(~x,data=aggregate(obsvars$value,by=list(obsvars$fleet),FUN=min)))
order <- rev(orderBy(~x,data=aggregate(obsvars$value,by=list(obsvars$fleet),FUN=min))$Group.1[-1])


BST.sams <- list()
for(iTun in order){
  notmin1 <- which(BST.ctrl@cor.obs[iTun,] != -1)
  if(length(notmin1)>0){
    BST.ctrl@cor.obs[iTun,notmin1] <- levels(order)[an(iTun)]
  } else {
    BST.ctrl@cor.obs[iTun,] <- which(levels(order)==iTun) + 101
  }
  
  idx <- which(rownames(BST.ctrl@cor.obs)==iTun)
  BST.ctrl@cor.obs.Flag[idx] <- as.factor("AR")
  BST.ctrl    <- update(BST.ctrl)

  output              <- capture.output(BST.sam             <- (FLSAM(BST,BST.tun,BST.ctrl,starting.values=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))))
  BST.sams[[iTun]] <- BST.sam
}
BST.sams <- as(BST.sams,"FLSAMs")
```

This results in the following AIC values: `r AIC(BST.sams)`
Best to also run retrospectives and leave-on-out for these, just to make sure the model doesn't get any worse from adding the correlation structures.

```{r, eval=T, echo=TRUE, message=FALSE, warning=FALSE}
BST.LOO     <- looi(BST,BST.tun,BST.ctrl,type="loo")
BST.retro   <- manualRetro(BST.sam,BST,BST.tun,BST.ctrl,sam.init=init.sam,map=list(logSdLogN=as.factor(c(-1.5,NA))))

print(mean(mohns.rho(BST.retro[1:4],ref.year=2018,type="ssb",span=3)[1:3,1]))
print(mean(mohns.rho(BST.retro[1:4],ref.year=2018,type="fbar",span=3)[1:3,1]))
print(mean(mohns.rho(BST.retro[1:4],ref.year=2018,type="rec",span=3)[1:3,1]))
```



